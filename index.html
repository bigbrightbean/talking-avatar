<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<title>Miss Maggie</title>

<style>
body {
  font-family: 'Comic Sans MS', Arial, sans-serif;
  text-align: center;
  background: #f0f8ff;
  padding: 40px;
}

h1 { color: #ff6600; }

#avatar {
  width: 220px;
  margin: 20px auto;
}

button {
  font-size: 20px;
  padding: 18px 30px;
  border: none;
  border-radius: 50px;
  cursor: pointer;
  color: white;
  box-shadow: 0 8px #666;
  margin: 8px;
}
button:active {
  box-shadow: 0 4px #444;
  transform: translateY(4px);
}

#talkBtn { background: #4CAF50; }
#talkBtn.orange { background: #FF9933; }
#shBtn { background: #9C27B0; }
#listenBtn { background: #2196F3; }

#text {
  font-size: 18px;
  margin-top: 20px;
  min-height: 110px;
}
</style>
</head>

<body>

<h1>Miss Maggie</h1>

<img id="avatar" src="images/teacher-mouth1.png">

<br>
<button id="talkBtn">üé§ Talk</button>
<button id="shBtn">üü£ SH</button>
<button id="listenBtn">üîÅ Listen again</button>

<div id="text"></div>

<script>
/* ================= CONFIG ================= */
const workerURL = "https://talking-avatar.bigbrightbean.workers.dev/";
const SH_WORDS = ["fish", "shell", "shop"];

/* ================= STATE ================= */
let inSHLesson = false;
let lessonQueue = [];
let lessonIndex = 0;
let waitingForAnswer = false;

let recognizing = false;
let recognition;
let transcriptText = "";

/* ================= ELEMENTS ================= */
const avatar = document.getElementById("avatar");
const talkBtn = document.getElementById("talkBtn");
const shBtn = document.getElementById("shBtn");
const listenBtn = document.getElementById("listenBtn");
const textDiv = document.getElementById("text");

const SpeechRecognition =
  window.SpeechRecognition || window.webkitSpeechRecognition;

/* ================= AVATAR ================= */
let mouthTimer = null;

function startAvatarTalking() {
  stopAvatarTalking();
  mouthTimer = setInterval(() => {
    const r = Math.random();
    avatar.src =
      r < 0.3 ? "images/teacher-mouth1.png" :
      r < 0.7 ? "images/teacher-mouth2.png" :
                "images/teacher-mouth3.png";
  }, 120 + Math.random() * 120);
}

function stopAvatarTalking() {
  clearInterval(mouthTimer);
  avatar.src = "images/teacher-mouth1.png";
}

/* ================= AUDIO ================= */
function playAudio(src, onEnd) {
  const audio = new Audio(src);
  startAvatarTalking();
  audio.onended = () => {
    stopAvatarTalking();
    if (onEnd) onEnd();
  };
  audio.play();
}

/* ================= PHONICS ================= */
function getPhonemeFile(word) {
  return word === "fish" ? "audio/phonemes/f_i_sh.m4a" :
         word === "shell" ? "audio/phonemes/sh_e_ll.m4a" :
                            "audio/phonemes/sh_o_p.m4a";
}

function playBlendingPrompt() {
  const word = lessonQueue[lessonIndex];
  textDiv.innerText = "Miss Maggie: Let‚Äôs blend these sounds. Listen carefully!";
  playAudio(getPhonemeFile(word), () => {
    textDiv.innerText += "\nWhat word does it make?";
    waitingForAnswer = true;
  });
}

/* ================= RECORDING ================= */
function startRecognition() {
  recognition = new SpeechRecognition();
  recognition.lang = "en-US";
  recognition.continuous = true;

  recognition.onresult = e => {
    transcriptText = "";
    for (let i = 0; i < e.results.length; i++) {
      transcriptText += e.results[i][0].transcript + " ";
    }
    transcriptText = transcriptText.toLowerCase();
    textDiv.innerText = "You said: " + transcriptText;
  };

  recognition.onend = () => {
    if (recognizing) recognition.start();
  };

  recognition.start();
}

function stopRecognition() {
  if (recognition) recognition.stop();
}

/* ================= CHATGPT ================= */
async function getMaggieReply(payload) {
  const res = await fetch(workerURL, {
    method: "POST",
    headers: { "Content-Type": "application/json" },
    body: JSON.stringify(payload)
  });
  const data = await res.json();
  return data.reply;
}

/* ================= CHECK ANSWER ================= */
async function checkAnswer() {
  if (!inSHLesson || !waitingForAnswer) return;

  const word = lessonQueue[lessonIndex];
  const isCorrect = transcriptText.includes(word);

  const reply = await getMaggieReply({
    type: "blending_feedback",
    target: word,
    correct: isCorrect
  });

  textDiv.innerText = "Miss Maggie: " + reply;

  playAudio(getPhonemeFile(word), () => {
    playAudio(`audio/words/${word}.m4a`, () => {
      textDiv.innerText += "\nAre you ready for the next one?";
      waitingForAnswer = false;
    });
  });
}

/* ================= BUTTONS ================= */
talkBtn.onclick = () => {
  if (!recognizing) {
    recognizing = true;
    transcriptText = "";
    talkBtn.classList.add("orange");
    talkBtn.innerText = "üé§ Listening...";
    startRecognition();
  } else {
    recognizing = false;
    talkBtn.classList.remove("orange");
    talkBtn.innerText = "üé§ Talk";
    stopRecognition();
    checkAnswer();
  }
};

shBtn.onclick = async () => {
  if (!inSHLesson) {
    inSHLesson = true;
    lessonQueue = [...SH_WORDS].sort(() => Math.random() - 0.5);
    lessonIndex = 0;
    playBlendingPrompt();
    return;
  }

  if (!waitingForAnswer) {
    lessonIndex++;
    if (lessonIndex < lessonQueue.length) {
      playBlendingPrompt();
    } else {
      const reply = await getMaggieReply({
        type: "lesson_complete",
        words: lessonQueue
      });
      textDiv.innerText = "Miss Maggie: " + reply;
      inSHLesson = false;
    }
  }
};

listenBtn.onclick = () => {
  if (inSHLesson) playBlendingPrompt();
};

/* ================= START ================= */
textDiv.innerText =
  "Miss Maggie: Hello! Talk to me, or press the SH button to start blending!";
</script>

</body>
</html>
