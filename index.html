<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<title>Miss Maggie</title>

<style>
body {
  font-family: 'Comic Sans MS', Arial, sans-serif;
  text-align: center;
  background: #f0f8ff;
  padding: 40px;
}

h1 { color: #ff6600; }

#avatar {
  width: 220px;
  margin: 20px auto;
}

#talkBtn {
  font-size: 20px;
  padding: 18px 30px;
  border: none;
  border-radius: 50px;
  cursor: pointer;
  color: white;
  background: #4CAF50;
  box-shadow: 0 8px #666;
}
#talkBtn.orange { background: #FF9933; }
#talkBtn:active {
  box-shadow: 0 4px #444;
  transform: translateY(4px);
}

#text {
  font-size: 18px;
  margin-top: 20px;
  min-height: 100px;
}
</style>
</head>

<body>

<h1>Miss Maggie</h1>
<img id="avatar" src="images/teacher-mouth1.png">
<br>
<button id="talkBtn">üé§ Talk</button>
<div id="text"></div>

<script>
/* ================= CONFIG ================= */
const workerURL = "https://talking-avatar.bigbrightbean.workers.dev/";
const TARGETS = ["fish", "shell", "shop"];

/* ================= STATE ================= */
let mode = "chat"; // chat | lesson
let currentIndex = 0;
let currentTarget = TARGETS[0];

let recognizing = false;
let recognition;
let transcriptText = "";

/* ================= ELEMENTS ================= */
const avatar = document.getElementById("avatar");
const talkBtn = document.getElementById("talkBtn");
const textDiv = document.getElementById("text");
const SpeechRecognition =
  window.SpeechRecognition || window.webkitSpeechRecognition;

/* ================= AVATAR MOUTH ================= */
let mouthTimer = null;

function startAvatarTalking() {
  stopAvatarTalking();
  mouthTimer = setInterval(() => {
    const r = Math.random();
    if (r < 0.2) avatar.src = "images/teacher-mouth1.png";
    else if (r < 0.7) avatar.src = "images/teacher-mouth2.png";
    else avatar.src = "images/teacher-mouth3.png";
  }, 120 + Math.random() * 120);
}

function stopAvatarTalking() {
  clearInterval(mouthTimer);
  avatar.src = "images/teacher-mouth1.png";
}

/* ================= AUDIO ================= */
function playAudio(src, onEnd) {
  const audio = new Audio(src);
  startAvatarTalking();
  audio.onended = () => {
    stopAvatarTalking();
    if (onEnd) onEnd();
  };
  audio.play();
}

/* ================= LESSON PROMPT ================= */
function askQuestion() {
  const prompt =
    currentTarget === "fish" ? "f / i / sh" :
    currentTarget === "shell" ? "sh / e / ll" :
    "sh / o / p";

  textDiv.innerText =
    `Miss Maggie: Can you blend these sounds‚Ä¶ ${prompt}? What word does it make?`;
}

/* ================= RECORDING ================= */
function startRecognition() {
  recognition = new SpeechRecognition();
  recognition.lang = "en-US";
  recognition.continuous = true;

  recognition.onresult = e => {
    transcriptText = "";
    for (let i = 0; i < e.results.length; i++) {
      transcriptText += e.results[i][0].transcript + " ";
    }
    transcriptText = transcriptText.toLowerCase();
    textDiv.innerText = "You said: " + transcriptText;
  };

  recognition.onend = () => {
    if (recognizing) recognition.start();
  };

  recognition.start();
}

function stopRecognition() {
  if (recognition) recognition.stop();
}

/* ================= CHATGPT ================= */
async function getMaggieReply(payload) {
  const res = await fetch(workerURL, {
    method: "POST",
    headers: { "Content-Type": "application/json" },
    body: JSON.stringify(payload)
  });
  const data = await res.json();
  return data.reply;
}

/* ================= TRIGGER ================= */
function isLessonTrigger(text) {
  return text.includes("start") &&
         text.includes("sh") &&
         text.includes("blending");
}

/* ================= FINAL TRANSCRIPT ================= */
async function handleFinalTranscript() {
  const t = transcriptText;

  /* ---- CHAT MODE ---- */
  if (mode === "chat") {
    if (isLessonTrigger(t)) {
      mode = "lesson";
      currentIndex = 0;
      currentTarget = TARGETS[0];
      textDiv.innerText = "Miss Maggie: Yay! Let‚Äôs start our sh blending lesson!";
      setTimeout(askQuestion, 800);
      return;
    }

    const reply = await getMaggieReply({
      type: "free_chat",
      message: t
    });

    textDiv.innerText = "Miss Maggie: " + reply;
    return;
  }

  /* ---- LESSON MODE ---- */
  checkAnswer();
}

/* ================= CHECK ANSWER ================= */
async function checkAnswer() {
  const isCorrect = transcriptText.includes(currentTarget);

  const reply = await getMaggieReply({
    type: "blending_feedback",
    target: currentTarget,
    correct: isCorrect
  });

  textDiv.innerText = "Miss Maggie: " + reply;

  const phonemeFile =
    currentTarget === "fish" ? "audio/phonemes/f_i_sh.m4a" :
    currentTarget === "shell" ? "audio/phonemes/sh_e_ll.m4a" :
    "audio/phonemes/sh_o_p.m4a";

  const wordFile = `audio/words/${currentTarget}.m4a`;

  playAudio(phonemeFile, () => {
    playAudio(wordFile, nextQuestion);
  });
}

/* ================= NEXT QUESTION ================= */
async function nextQuestion() {
  currentIndex++;

  if (currentIndex < TARGETS.length) {
    currentTarget = TARGETS[currentIndex];
    setTimeout(askQuestion, 800);
  } else {
    const reply = await getMaggieReply({
      type: "lesson_complete",
      words: TARGETS
    });
    textDiv.innerText = "Miss Maggie: " + reply;
    mode = "chat"; // return to free chat
  }
}

/* ================= TALK BUTTON ================= */
talkBtn.onclick = () => {
  if (!recognizing) {
    recognizing = true;
    transcriptText = "";
    talkBtn.classList.add("orange");
    talkBtn.innerText = "üé§ Listening...";
    startRecognition();
  } else {
    recognizing = false;
    talkBtn.classList.remove("orange");
    talkBtn.innerText = "üé§ Talk";
    stopRecognition();
    handleFinalTranscript();
  }
};

/* ================= START ================= */
textDiv.innerText =
  "Miss Maggie: Hello! You can talk to me about anything, or say ‚Äústart sh blending‚Äù!";
</script>

</body>
</html>
